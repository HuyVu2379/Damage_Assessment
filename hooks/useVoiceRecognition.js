import { useState, useEffect } from 'react';
import { Alert } from 'react-native';
import speechToTextService from '../services/speechToText';

export const useVoiceRecognition = (setInputText, setIsLoading) => {
    const [isListening, setIsListening] = useState(false);
    const [isTranscribing, setIsTranscribing] = useState(false);

    useEffect(() => {
        // Cleanup function when component unmounts
        return () => {
            speechToTextService.cleanup();
        };
    }, []);

    const startListening = async () => {
        try {
            console.log('ðŸŽ™ï¸ Starting voice recognition...');
            setIsLoading && setIsLoading(true);
            setIsListening(true);

            const success = await speechToTextService.startRecording();
            if (!success) {
                throw new Error('Failed to start recording');
            }

            console.log('âœ… Voice recording started successfully');
        } catch (error) {
            console.error('âŒ Error starting voice recognition:', error);
            setIsListening(false);
            setIsLoading && setIsLoading(false);

            let errorMessage = 'KhÃ´ng thá»ƒ báº¯t Ä‘áº§u ghi Ã¢m';
            if (error.message.includes('permission')) {
                errorMessage = 'Cáº§n quyá»n truy cáº­p microphone Ä‘á»ƒ ghi Ã¢m';
            }

            Alert.alert('Lá»—i ghi Ã¢m', errorMessage);
        }
    };

    const stopListening = async () => {
        try {
            if (!isListening) {
                console.log('âš ï¸ Not currently listening, nothing to stop');
                return;
            }

            console.log('ðŸ›‘ Stop requested - UI will update immediately');

            // Immediately update UI states for fast feedback
            setIsListening(false);
            setIsTranscribing(true);

            console.log('ðŸ›‘ Stopping recording and starting transcription...');

            const audioUri = await speechToTextService.stopRecording();

            if (audioUri) {
                console.log('âœ… Audio file ready, starting transcription...');
                // Transcribe the audio using Deepgram Speech-to-Text
                const transcript = await speechToTextService.transcribeAudio(audioUri);

                if (transcript && transcript.trim()) {
                    setInputText(transcript.trim());
                    console.log('âœ… Transcription completed:', transcript);
                } else {
                    console.log('âš ï¸ Empty transcription result');
                    Alert.alert('ThÃ´ng bÃ¡o', 'KhÃ´ng nháº­n diá»‡n Ä‘Æ°á»£c giá»ng nÃ³i. Vui lÃ²ng thá»­ láº¡i.');
                }
            } else {
                console.log('âŒ No audio URI returned from recording');
                Alert.alert('Lá»—i', 'KhÃ´ng cÃ³ dá»¯ liá»‡u Ã¢m thanh Ä‘á»ƒ xá»­ lÃ½.');
            }
        } catch (error) {
            console.error('âŒ Error stopping voice recognition:', error);
            Alert.alert('Lá»—i', 'CÃ³ lá»—i xáº£y ra khi xá»­ lÃ½ Ã¢m thanh. Vui lÃ²ng thá»­ láº¡i.');
        } finally {
            setIsListening(false);
            setIsTranscribing(false);
            setIsLoading && setIsLoading(false);
            console.log('ðŸ Voice recognition process completed');
        }
    };

    const cancelListening = async () => {
        try {
            await speechToTextService.cancelRecording();
            setIsListening(false);
            setIsTranscribing(false);
            setIsLoading && setIsLoading(false);
            console.log('Voice recognition cancelled');
        } catch (error) {
            console.error('Error canceling voice recognition:', error);
            setIsListening(false);
            setIsTranscribing(false);
            setIsLoading && setIsLoading(false);
        }
    };

    return {
        isListening,
        isTranscribing,
        startListening,
        stopListening,
        cancelListening,
    };
};
